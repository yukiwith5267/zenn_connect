---
title: "Zoomを自動入退出して、授業スライドを自動スクショするプログラムを作りたい。"
emoji: "🐷"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: []
published: false
---

## はじめに
この記事は、[【Python】朝風呂に入りながらZoomを自動入退出](https://zenn.dev/yukitezuka/articles/53ffd07749d0ec) の続きです。

前回は、指定した時間に入室して、一定時間後にzoomのウィンドウを閉じることによって退出するプログラムを実現した。

これに、授業スライドを自動スクショする機能を追加したいと思った。理由は、期末試験が近づいてきたので、教授の手書きのメモを保管しておきたいと思ったからである。

## 手法
2通りの方法を思いついた。

まず一つ目は、画面を監視していて一定以上の変化があった場合にスクショする。
具体的には、OpenCVで動体検知して、例えば画面全体の5割が変化したら、スクショをするような感じ。

ただ、これには閾値の微調整が必要であり、労力が必要である。加えて、図1のように隅っこに教授が映る場合は問題ないのだが、図2のように画面全体に教授が写って授業をするような場合は、教授の動きが大きく反映してしまうた有用ではない。

![図1](/images/885ab465c79658/fig1.jpg)
*図1: 教授が隅っこに映っている場合*

![図2](/images/885ab465c79658/fig2.jpg)
*図2: 教授が画面全体に映りながら授業をしている場合*


そこで2つ目。ベタな方法だが、一定間隔でスクショを撮る方法である。
こちらは、教授の動きに関係なく、安定してスクショを撮ることができる。



```python
import subprocess
import time
import cv2
import numpy as np
from PIL import ImageGrab

# スクリーンショット保存先のディレクトリパス
SCREENSHOT_DIR = "/screenshot/zoom"

# 動体検知のしきい値（画面全体の変化の割合）
MOTION_THRESHOLD = 0.5  # Adjust this threshold as needed

def join_zoom_meeting(meeting_id, password):
    command = f"zoommtg://zoom.us/join?action=join&confno={meeting_id}&pwd={password}"
    subprocess.call(["open", command])

def close_zoom_window():
    subprocess.call(["pkill", "zoom.us"])

def capture_screenshot():
    screenshot = ImageGrab.grab()
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    screenshot_path = f"{SCREENSHOT_DIR}/screenshot_{timestamp}.png"
    screenshot.save(screenshot_path)
    print(f"Screenshot saved: {screenshot_path}")

def main():
    meeting_id = "YOUR_MEETING_ID"
    password = "YOUR_PASSWORD"
    target_time = "01:10:00"  # 開始する時間を指定 (24時間形式)
    meeting_duration = 1  # ミーティングの持続時間を指定 (分単位)
    motion_frames = []
    
    while True:
        current_time = time.strftime("%H:%M:%S")
        if current_time >= target_time:
            join_zoom_meeting(meeting_id, password)
            start_time = time.time()
            previous_frame = None  # 前回のフレームを保持する変数
            motion_detected = False  # 変化検知のフラグ
            
            while True:
                # スクリーンショットを取得し、前回のフレームと比較する
                screenshot = np.array(ImageGrab.grab())
                gray = cv2.cvtColor(screenshot, cv2.COLOR_BGR2GRAY)
                gray = cv2.GaussianBlur(gray, (21, 21), 0)
                
                if previous_frame is None:
                    previous_frame = gray
                    continue
                
                frame_delta = cv2.absdiff(previous_frame, gray)
                thresh = cv2.threshold(frame_delta, 30, 255, cv2.THRESH_BINARY)[1]
                thresh = cv2.dilate(thresh, None, iterations=2)
                contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                
                for contour in contours:
                    if cv2.contourArea(contour) > 500:
                        motion_detected = True
                        break
                else:  # add an else block here
                     motion_detected = False

                
                if motion_detected:
                    elapsed_time = time.time() - start_time
                    
                    if elapsed_time >= meeting_duration * 60:
                        capture_screenshot()
                        close_zoom_window()
                        break
                else:
                    motion_detected = False
                
                previous_frame = gray
                time.sleep(0.1)
            
            break
        else:
            time.sleep(1)

if __name__ == "__main__":
    main()


```